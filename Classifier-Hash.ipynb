{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92bc9803-140d-42f3-a96e-f11ab63fd799",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.16.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow)\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.5.4-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow)\n",
      "  Using cached h5py-3.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow)\n",
      "  Using cached ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/.qbraid/environments/qbraid_000000/pyenv/lib/python3.11/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/.qbraid/environments/qbraid_000000/pyenv/lib/python3.11/site-packages (from tensorflow) (23.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Using cached protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/.qbraid/environments/qbraid_000000/pyenv/lib/python3.11/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /opt/.qbraid/environments/qbraid_000000/pyenv/lib/python3.11/site-packages (from tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/.qbraid/environments/qbraid_000000/pyenv/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/.qbraid/environments/qbraid_000000/pyenv/lib/python3.11/site-packages (from tensorflow) (4.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/.qbraid/environments/qbraid_000000/pyenv/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Using cached grpcio-1.62.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow)\n",
      "  Using cached tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.0.0 (from tensorflow)\n",
      "  Using cached keras-3.2.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.36.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/.qbraid/environments/qbraid_000000/pyenv/lib/python3.11/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/envs/py311/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in /opt/.qbraid/environments/qbraid_000000/pyenv/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
      "Collecting namex (from keras>=3.0.0->tensorflow)\n",
      "  Using cached namex-0.0.7-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.0.0->tensorflow)\n",
      "  Using cached optree-0.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (45 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/.qbraid/environments/qbraid_000000/pyenv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/.qbraid/environments/qbraid_000000/pyenv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/.qbraid/environments/qbraid_000000/pyenv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/.qbraid/environments/qbraid_000000/pyenv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Using cached Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Using cached werkzeug-3.0.2-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/.qbraid/environments/qbraid_000000/pyenv/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/.qbraid/environments/qbraid_000000/pyenv/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/.qbraid/environments/qbraid_000000/pyenv/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/.qbraid/environments/qbraid_000000/pyenv/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
      "Using cached tensorflow-2.16.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Using cached gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached grpcio-1.62.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n",
      "Using cached h5py-3.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "Using cached keras-3.2.1-py3-none-any.whl (1.1 MB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "Using cached ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "Using cached protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "Using cached tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "Using cached tensorflow_io_gcs_filesystem-0.36.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "Using cached termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Using cached Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "Using cached werkzeug-3.0.2-py3-none-any.whl (226 kB)\n",
      "Using cached namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
      "Using cached optree-0.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (312 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, ml-dtypes, markdown, h5py, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.5.4 google-pasta-0.2.0 grpcio-1.62.1 h5py-3.11.0 keras-3.2.1 libclang-18.1.1 markdown-3.6 ml-dtypes-0.3.2 namex-0.0.7 optree-0.11.0 protobuf-4.25.3 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.1 tensorflow-io-gcs-filesystem-0.36.0 termcolor-2.4.0 werkzeug-3.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "181fb31a-37fc-45c5-aa32-b34d0b2b3d39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation accuracy: 0.8633333444595337\n",
      "Best parameters: {'learning_rate': 0.001, 'dropout_rate': 0.5}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "import hashlib\n",
    "from collections import Counter\n",
    "\n",
    "# Dictionary to store device hashes\n",
    "device_hashes = {}\n",
    "\n",
    "# Function to generate a SHA-256 hash for the given device label\n",
    "def generate_hash(device_label):\n",
    "    if device_label not in device_hashes:\n",
    "        hashed_value = hashlib.sha256(str(device_label).encode()).hexdigest()\n",
    "        device_hashes[device_label] = hashed_value\n",
    "    return device_hashes[device_label]\n",
    "\n",
    "# Function to read and preprocess data from a file\n",
    "def read_and_preprocess_data(file_path, has_labels=True):\n",
    "    X = []\n",
    "    y = []\n",
    "    encoding = 'utf-8-sig' if not has_labels else 'utf-8'  # Use 'utf-8-sig' for new_data if necessary\n",
    "    with open(file_path, 'r', encoding=encoding) as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split(' ')\n",
    "            features = np.array([int(bit) for bit in parts[0]], dtype=int)\n",
    "            X.append(features)\n",
    "            if has_labels and len(parts) > 1:\n",
    "                y.append(int(parts[1]))\n",
    "    X = np.array(X)\n",
    "    if has_labels:\n",
    "        y = np.array(y)\n",
    "        num_classes = np.unique(y).size\n",
    "        y_categorical = keras.utils.to_categorical(y - 1, num_classes=num_classes)\n",
    "        return X, y_categorical, num_classes\n",
    "    return X, None, None\n",
    "\n",
    "# Function to create the model\n",
    "def create_model(input_shape, num_classes, learning_rate, dropout_rate):\n",
    "    model = keras.Sequential([\n",
    "        keras.Input(shape=(input_shape,)),\n",
    "        layers.Reshape((input_shape, 1)),  # Needed for Conv1D\n",
    "        layers.Conv1D(32, kernel_size=3, activation='relu', padding='same'),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Training the model\n",
    "print(\"Training the model...\")\n",
    "X_train, y_train_categorical, num_classes = read_and_preprocess_data('DoraHack/training_data.txt', has_labels=True)\n",
    "input_shape = X_train.shape[1]\n",
    "best_accuracy = 0\n",
    "best_params = {}\n",
    "\n",
    "\n",
    "learning_rates = [0.01, 0.001, 0.0001]  # Different learning rates to try\n",
    "dropout_rates = [0.3, 0.5, 0.7]  # Different dropout rates to try\n",
    "\n",
    "for lr in [0.01, 0.001, 0.0001]:\n",
    "    for dr in [0.3, 0.5, 0.7] :\n",
    "        model = create_model(input_shape, num_classes, lr, dr)\n",
    "        history = model.fit(X_train, y_train_categorical, epochs=10, validation_split=0.1, verbose=0)\n",
    "        val_accuracy = max(history.history['val_accuracy'])\n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            best_params = {'learning_rate': lr, 'dropout_rate': dr}\n",
    "            model.save('best_model.h5')\n",
    "\n",
    "print(\"Best validation accuracy:\", best_accuracy)\n",
    "print(\"Best parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81416863-ec5d-408c-b651-4f2ad6b8d69d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting new data...\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Label counts and percentages:\n",
      "Label 3 appears 4338 times (54.23%), Blockchain Address: 4e07408562bedb8b60ce05c1decfe3ad16b72230967de01f640b7e4729b49fce\n",
      "Label 1 appears 3627 times (45.34%), Blockchain Address: 6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b\n",
      "Label 2 appears 35 times (0.44%), Blockchain Address: d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f90da3a666eec13ab35\n"
     ]
    }
   ],
   "source": [
    "# Predicting new data\n",
    "print(\"Predicting new data...\")\n",
    "model = keras.models.load_model('DoraHack/bestmodel.h5')\n",
    "X_new, _, _ = read_and_preprocess_data('DoraHack/test_1_simulator.txt', has_labels=False)\n",
    "predictions = model.predict(X_new)\n",
    "predicted_labels = np.argmax(predictions, axis=1) + 1  # Labels are 1-based\n",
    "\n",
    "# Count the occurrences of each label and calculate percentages\n",
    "total_samples = len(predicted_labels)\n",
    "label_counts = Counter(predicted_labels)\n",
    "print(\"Label counts and percentages:\")\n",
    "for label, count in label_counts.items():\n",
    "    percentage = (count / total_samples) * 100\n",
    "    hash_address = generate_hash(str(label))\n",
    "    print(f\"Label {label} appears {count} times ({percentage:.2f}%), Blockchain Address: {hash_address}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b03bdfc-6889-4121-9b72-fe1b84f8fda6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [Default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
